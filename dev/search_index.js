var documenterSearchIndex = {"docs":
[{"location":"api/#Api","page":"API","title":"Api","text":"","category":"section"},{"location":"api/#LearningToOptimize","page":"API","title":"LearningToOptimize","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [LearningToOptimize]","category":"page"},{"location":"api/#LearningToOptimize.FullyConnected-Tuple{Int64, Vector{Int64}, Int64}","page":"API","title":"LearningToOptimize.FullyConnected","text":"FullyConnected(input_size::Int, hidden_sizes::Vector{Int}, output_size::Int)::FullyConnected\n\nCreate a fully connected neural network with input_size inputs, hidden_sizes hidden layers and output_size outputs. Adds a pass through layer for each layer.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.ProblemIterator","page":"API","title":"LearningToOptimize.ProblemIterator","text":"ProblemIterator(ids::Vector{UUID}, pairs::Dict{VariableRef, Vector{Real}})\n\nIterator for optimization problem instances.\n\n\n\n\n\n","category":"type"},{"location":"api/#LearningToOptimize.Recorder","page":"API","title":"LearningToOptimize.Recorder","text":"Recorder(filename; primal_variables=[], dual_variables=[], filterfn=(model)-> termination_status(model) == MOI.OPTIMAL)\n\nRecorder of optimization problem solutions.\n\n\n\n\n\n","category":"type"},{"location":"api/#LearningToOptimize.box_sampler-Union{Tuple{F}, Tuple{T}, Tuple{T, F}, Tuple{T, F, AbstractVector{T}}} where {T<:Real, F<:Integer}","page":"API","title":"LearningToOptimize.box_sampler","text":"function box_sampler(\n    original_parameter::T,\n    num_s::F,\n    range_p::AbstractVector{T}=0.8:0.01:1.25,\n) where {T<:Real,F<:Integer}\n\nUniformly sample values around the original parameter value over a discrete range inside a box.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.general_sampler-Union{Tuple{AbstractString}, Tuple{T}} where T<:LearningToOptimize.FileType","page":"API","title":"LearningToOptimize.general_sampler","text":"general_sampler(\n    file::AbstractString;\n    samplers::Vector{Function}=[\n        (original_parameters) -> scaled_distribution_sampler(original_parameters, 1000),\n        LearningToOptimize.line_sampler, \n        (original_parameters) -> box_sampler(original_parameters, 10),\n    ],\n    batch_id::UUID=uuid1(),\n    save_file::AbstractString=split(file, \".mof.json\")[1] * \"_input_\" * string(batch_id),\n    filetype::Type{T}=ArrowFile\n) where {T<:FileType}\n\nThis function is a general sampler that uses a set of samplers to sample the parameter space.  It loads the underlying model from file and samples the parameters. It saves the sampled parameters to save_file.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.general_sampler-Union{Tuple{Vector{T}}, Tuple{T}} where T<:Real","page":"API","title":"LearningToOptimize.general_sampler","text":"function general_sampler(\n    original_parameters::Vector{T};\n    samplers::Vector{Function}=[\n        (original_parameters) -> scaled_distribution_sampler(original_parameters, 1000),\n        LearningToOptimize.line_sampler, \n        (original_parameters) -> box_sampler(original_parameters, 10),\n    ]\n) where {T<:Real}\n\nThis function is a general sampler that uses a set of samplers to sample the parameter space.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.inconvexhull-Tuple{Matrix{Float64}, Matrix{Float64}, Any}","page":"API","title":"LearningToOptimize.inconvexhull","text":"inconvexhull(training_set::Matrix{Float64}, test_set::Matrix{Float64})\n\nCheck if new points are inside the convex hull of the given points. Solves a linear programming problem to check if the points are inside the convex hull.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.line_sampler-Union{Tuple{F}, Tuple{T}, Tuple{Vector{T}, AbstractVector{F}}, Tuple{Vector{T}, AbstractVector{F}, AbstractVector{T}}} where {T<:Real, F<:Integer}","page":"API","title":"LearningToOptimize.line_sampler","text":"function line_sampler(\n    original_parameters::Vector{T},\n    parameter_indexes::Vector{F},\n    range_p::AbstractVector{T},\n) where {T<:Real,F<:Integer}\n\nThis sampler returns a set of parameters that for a line in one dimension of the parameter space.  The idea is to change the value of one parameter and keep the rest constant.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.load_parameters-Tuple{AbstractString}","page":"API","title":"LearningToOptimize.load_parameters","text":"load_parameters(file::AbstractString)\n\nLoad the parameters from a saved jump model.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.load_parameters-Tuple{JuMP.Model}","page":"API","title":"LearningToOptimize.load_parameters","text":"load_parameters(model::JuMP.Model)\n\nLoad the parameters from a JuMP model.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.make_convex!-Tuple{Flux.PairwiseFusion}","page":"API","title":"LearningToOptimize.make_convex!","text":"function make_convex!(chain::PairwiseFusion; tol = 1e-6)\n\nMake a PairwiseFusion model convex by making sure all dense layers (a part from the first) have positive weights. This procedure only makes sense for single output fully connected models.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.make_convex!-Tuple{FullyConnected}","page":"API","title":"LearningToOptimize.make_convex!","text":"function make_convex!(model::FullyConnected; tol = 1e-6)\n\nMake a FullyConnected model convex by making sure all dense layers (a part from the first) have positive weights. This procedure only makes sense for single output fully connected models.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.record-Tuple{Recorder{ArrowFile}, Base.UUID}","page":"API","title":"LearningToOptimize.record","text":"record(recorder::Recorder{ArrowFile}, id::UUID)\n\nRecord optimization problem solution to an Arrow file.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.record-Tuple{Recorder{CSVFile}, Base.UUID}","page":"API","title":"LearningToOptimize.record","text":"record(recorder::Recorder{CSVFile}, id::UUID)\n\nRecord optimization problem solution to a CSV file.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.save-Union{Tuple{T}, Tuple{LearningToOptimize.AbstractProblemIterator, AbstractString, Type{T}}} where T<:LearningToOptimize.FileType","page":"API","title":"LearningToOptimize.save","text":"save(problem_iterator::ProblemIterator, filename::AbstractString, file_type::Type{T})\n\nSave optimization problem instances to a file.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.scaled_distribution_sampler-Union{Tuple{F}, Tuple{T}, Tuple{Vector{T}, F}} where {T<:Real, F<:Integer}","page":"API","title":"LearningToOptimize.scaled_distribution_sampler","text":"function scaled_distribution_sampler(\n    original_parameters::Vector{T},\n    num_s::F;\n    rng::AbstractRNG=Random.GLOBAL_RNG,\n    scaler_multiplier::Distribution=Uniform(0.8, 1.25),\n    distribution::Distribution=MvLogNormal(fill(-(1.05 .^ 2) ./ 2.0, length(original_parameters)), 1.05)\n) where {T<:Real,F<:Integer}\n\nSample from a distribution and scale the parameters by a random value over a uniform distribution.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.solve_and_record-Tuple{ProblemIterator, Recorder, Integer}","page":"API","title":"LearningToOptimize.solve_and_record","text":"solve_and_record(problem_iterator::ProblemIterator, recorder::Recorder, idx::Integer)\n\nSolve an optimization problem and record the solution.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.solve_batch-Tuple{LearningToOptimize.AbstractProblemIterator, Any}","page":"API","title":"LearningToOptimize.solve_batch","text":"solve_batch(problem_iterator::AbstractProblemIterator, recorder)\n\nSolve a batch of optimization problems and record the solutions.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.update_model!-Tuple{JuMP.Model, Dict, Integer, Type{<:LearningToOptimize.AbstractParameterType}}","page":"API","title":"LearningToOptimize.update_model!","text":"update_model!(model::JuMP.Model, pairs::Dict, idx::Integer)\n\nUpdate the values of parameters in a JuMP model.\n\n\n\n\n\n","category":"method"},{"location":"api/#LearningToOptimize.update_model!-Tuple{Type{LearningToOptimize.POIParamaterType}, JuMP.Model, JuMP.VariableRef, Any}","page":"API","title":"LearningToOptimize.update_model!","text":"update_model!(model::JuMP.Model, p::VariableRef, val::Real)\n\nUpdate the value of a parameter in a JuMP model.\n\n\n\n\n\n","category":"method"},{"location":"arrow/#**Reading-from-and-Compressing-Arrow-Files**","page":"Arrow","title":"Reading from and Compressing Arrow Files","text":"","category":"section"},{"location":"arrow/#**Introduction**","page":"Arrow","title":"Introduction","text":"","category":"section"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"The package provides tools to work with Arrow files efficiently, allowing users to store and retrieve large datasets efficiently.","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"output_file = joinpath(save_path, \"$(case_name)_output_$(batch_id)\")\nrecorder = Recorder{filetype}(output_file)\nsuccessfull_solves = solve_batch(problem_iterator, recorder)","category":"page"},{"location":"arrow/#**Compressing-Arrow-Files**","page":"Arrow","title":"Compressing Arrow Files","text":"","category":"section"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"Since appending data to Arrow files is slow and inefficient,  each instance of data is stored in a separate file. Thefore, in this case, the output files will look like this:","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"<case_name>_output_<batch_id>_<instance_1_id>.arrow\n<case_name>_output_<batch_id>_<instance_2_id>.arrow\n...\n<case_name>_output_<batch_id>_<instance_n_id>.arrow","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"LearningToOptimize.jl supports compressing batches of Arrow files for streamlined storage and retrieval.","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"Use the LearningToOptimize.compress_batch_arrow function to compress a batch of Arrow files into a single file. This reduces disk usage and simplifies file management.","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"Function Signature:","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"LearningToOptimize.compress_batch_arrow(\n    save_path,\n    case_name;\n    keyword_all = \"output\",\n    batch_id = string(batch_id),\n    # keyword_any = [string(batch_id)]\n)","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"Arguments:\nsave_path: Path to save the compressed file.\ncase_name: Name of the case or batch.\nkeyword_all: Filter files containing this keyword (default: \"output\").\nbatch_id: Identifier for the batch of files.\nkeyword_any: Array of keywords to further filter files.","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"The compressed file will be saved as <case_name>_output_<batch_id>.arrow.","category":"page"},{"location":"arrow/#**Reading-Arrow-Files**","page":"Arrow","title":"Reading Arrow Files","text":"","category":"section"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"Arrow files can be read using Julia’s Arrow library, which provides a tabular interface for data access.","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"Example:","category":"page"},{"location":"arrow/","page":"Arrow","title":"Arrow","text":"using Arrow\n\n# Read compressed Arrow file\ndata = Arrow.Table(\"<case_name>_output_<batch_id>.arrow\")\n\n# Access data as a DataFrame\nusing DataFrames\ndf = DataFrame(data)\n\nprintln(\"DataFrame content:\")\nprintln(df)","category":"page"},{"location":"parametertype/#**Parameter-Types-for-Optimization-Problems**","page":"Parameter Type","title":"Parameter Types for Optimization Problems","text":"","category":"section"},{"location":"parametertype/#**Introduction**","page":"Parameter Type","title":"Introduction","text":"","category":"section"},{"location":"parametertype/","page":"Parameter Type","title":"Parameter Type","text":"When working with optimization problems, LearningToOptimize.jl supports multiple parameterization strategies. These strategies influence the behavior and performance of the solver and allow flexibility in retrieving information such as dual variables.","category":"page"},{"location":"parametertype/","page":"Parameter Type","title":"Parameter Type","text":"","category":"page"},{"location":"parametertype/#**Comparison**","page":"Parameter Type","title":"Comparison","text":"","category":"section"},{"location":"parametertype/","page":"Parameter Type","title":"Parameter Type","text":"Parameter Type Supported Problems Dual Support Performance Notes\nJuMPParameterType All Yes Moderate General-purpose; slower.\nJuMPNLPParameterType NLP Only No Fast Optimized for NLP problems.\nPOIParameterType (Default) Linear, Conic Yes Fast Requires POI-wrapped solvers.","category":"page"},{"location":"parametertype/","page":"Parameter Type","title":"Parameter Type","text":"","category":"page"},{"location":"parametertype/#**Supported-Parameter-Types**","page":"Parameter Type","title":"Supported Parameter Types","text":"","category":"section"},{"location":"parametertype/","page":"Parameter Type","title":"Parameter Type","text":"POIParameterType (Default):\nDescription:\nExtends MOI.Parameters for linear and conic problems.\nCompatible with solvers wrapped using ParametricOptInterface.\nSupports fetching duals w.r.t. parameters.\nLimitations:\nNot compatible with nonlinear solvers.\nUsage Example: Default behavior when using ProblemIterator without specifying param_type.\nJuMPParameterType:\nDescription:\nAdds a variable as a parameter with an additional constraint during solve_batch.\nSlower compared to other types but supports fetching duals w.r.t. the parameter.\nCompatible with all problem types.\nUsage Example:\nusing JuMP, LearningToOptimize\n\nmodel = JuMP.Model(HiGHS.Optimizer)\n@variable(model, x)\np = @variable(model, _p)\n@constraint(model, cons, x + _p >= 3)\n@objective(model, Min, 2x)\n\nnum_p = 10\nproblem_iterator = ProblemIterator(\n    Dict(p => collect(1.0:num_p));\n    param_type = LearningToOptimize.JuMPParameterType\n)\n\nrecorder = Recorder{ArrowFile}(\"output.arrow\"; primal_variables = [x], dual_variables = [cons])\nsolve_batch(problem_iterator, recorder)\nAdvantages:\nWorks with all solvers and problem types.\nDuals w.r.t. parameters are available.\nJuMPNLPParameterType:\nDescription:\nUtilizes MOI’s internal parameter structure.\nOptimized for speed but limited to nonlinear programming (NLP) problems.\nDoes not support fetching duals w.r.t. parameters.\nUsage Example:\nusing JuMP, LearningToOptimize\n\nmodel = JuMP.Model(Ipopt.Optimizer)\n@variable(model, x)\np = @variable(model, _p in MOI.Parameter(1.0))\n@constraint(model, cons, x + _p >= 3)\n@objective(model, Min, 2x)\n\nnum_p = 10\nproblem_iterator = ProblemIterator(\n    Dict(p => collect(1.0:num_p));\n    param_type = LearningToOptimize.JuMPNLPParameterType\n)\n\nrecorder = Recorder{ArrowFile}(\"output.arrow\"; primal_variables = [x], dual_variables = [cons])\nsolve_batch(problem_iterator, recorder)\nAdvantages:\nFast and efficient for NLP problems.\nNo external wrappers required.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = LearningToOptimize","category":"page"},{"location":"","page":"Home","title":"Home","text":"<div style=\"width:100%; height:150px;border-width:4px;border-style:solid;padding-top:25px;\n        border-color:#000;border-radius:10px;text-align:center;background-color:#99DDFF;\n        color:#000\">\n    <h3 style=\"color: black;\">Star us on GitHub!</h3>\n    <a class=\"github-button\" href=\"https://github.com/andrewrosemberg/LearningToOptimize.jl\" data-icon=\"octicon-star\" data-size=\"large\" data-show-count=\"true\" aria-label=\"Star andrewrosemberg/LearningToOptimize.jl on GitHub\" style=\"margin:auto\">Star</a>\n    <script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n</div>","category":"page"},{"location":"#LearningToOptimize","page":"Home","title":"LearningToOptimize","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for LearningToOptimize.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Learning to optimize (LearningToOptimize) package that provides basic functionalities to help fit proxy models for optimization.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"] add LearningToOptimize","category":"page"},{"location":"#Flowchart-Summary","page":"Home","title":"Flowchart Summary","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: flowchart)","category":"page"},{"location":"#Generate-Dataset","page":"Home","title":"Generate Dataset","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides a basic way of generating a dataset of the solutions of an optimization problem by varying the values of the parameters in the problem and recording it.","category":"page"},{"location":"#The-Problem-Iterator","page":"Home","title":"The Problem Iterator","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The user needs to first define a problem iterator:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# The problem to iterate over\nmodel = Model(() -> POI.Optimizer(HiGHS.Optimizer()))\n@variable(model, x)\np = @variable(model, p in MOI.Parameter(1.0)) # The parameter (defined using POI)\n@constraint(model, cons, x + p >= 3)\n@objective(model, Min, 2x)\n\n# The parameter values\nparameter_values = Dict(p => collect(1.0:10.0))\n\n# The iterator\nproblem_iterator = ProblemIterator(parameter_values)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The parameter values of the problem iterator can be saved by simply:","category":"page"},{"location":"","page":"Home","title":"Home","text":"save(problem_iterator, \"input_file\", CSVFile)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Which creates the following CSV:","category":"page"},{"location":"","page":"Home","title":"Home","text":"id p\n1 1.0\n2 2.0\n3 3.0\n4 4.0\n5 5.0\n6 6.0\n7 7.0\n8 8.0\n9 9.0\n10 10.0","category":"page"},{"location":"","page":"Home","title":"Home","text":"ps.: For illustration purpose, I have represented the id's here as integers, but in reality they are generated as UUIDs. ","category":"page"},{"location":"#The-Recorder","page":"Home","title":"The Recorder","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Then chose what values to record:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# CSV recorder to save the optimal primal and dual decision values\nrecorder = Recorder{CSVFile}(\"output_file.csv\", primal_variables=[x], dual_variables=[cons])\n\n# Finally solve all problems described by the iterator\nsolve_batch(problem_iterator, recorder)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Which creates the following CSV:","category":"page"},{"location":"","page":"Home","title":"Home","text":"id x dual_cons\n1 2.0 2.0\n2 1.0 2.0\n3 -0.0 2.0\n4 -1.0 2.0\n5 -2.0 2.0\n6 -3.0 2.0\n7 -4.0 2.0\n8 -5.0 2.0\n9 -6.0 2.0\n10 -7.0 2.0","category":"page"},{"location":"","page":"Home","title":"Home","text":"ps.: Ditto id's.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Similarly, there is also the option to save the database in arrow files:","category":"page"},{"location":"","page":"Home","title":"Home","text":"recorder = Recorder{ArrowFile}(\"output_file.arrow\", primal_variables=[x], dual_variables=[cons])","category":"page"},{"location":"#Learning-proxies","page":"Home","title":"Learning proxies","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In order to train models to be able to forecast optimization solutions from parameter values, one option is to use the package Flux.jl:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# read input and output data\ninput_data = CSV.read(\"input_file.csv\", DataFrame)\noutput_data = CSV.read(\"output_file.csv\", DataFrame)\n\n# Separate input and output variables\noutput_variables = output_data[!, Not(:id)]\ninput_features = innerjoin(input_data, output_data[!, [:id]], on = :id)[!, Not(:id)] # just use success solves\n\n# Define model\nmodel = Chain(\n    Dense(size(input_features, 2), 64, relu),\n    Dense(64, 32, relu),\n    Dense(32, size(output_variables, 2))\n)\n\n# Define loss function\nloss(x, y) = Flux.mse(model(x), y)\n\n# Convert the data to matrices\ninput_features = Matrix(input_features)'\noutput_variables = Matrix(output_variables)'\n\n# Define the optimizer\noptimizer = Flux.ADAM()\n\n# Train the model\nFlux.train!(loss, Flux.params(model), [(input_features, output_variables)], optimizer)\n\n# Make predictions\npredictions = model(input_features)","category":"page"},{"location":"#Coming-Soon","page":"Home","title":"Coming Soon","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Future features:","category":"page"},{"location":"","page":"Home","title":"Home","text":"ML objectives that penalize infeasible predictions;\nWarm-start from predicted solutions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"<!– ```@index","category":"page"},{"location":"","page":"Home","title":"Home","text":"\n\n<!-- ```@autodocs\nModules = [LearningToOptimize]","category":"page"},{"location":"","page":"Home","title":"Home","text":"–>","category":"page"}]
}
